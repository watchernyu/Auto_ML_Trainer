{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network Assignment: Image Classification on CIFAR 10\n",
    "In this assignment, you will design and implement a CNN model in Keras. We will use the CIFAR-10. Please note you **only need to use 1000 training examples** (CPU is much slower than GPU so we do not use the full dataset). Please complete the rest of the notebook by doing following tasks.\n",
    "\n",
    "- Build your network. Your network should have **at least 2 convolutional layers, 1 max pooling layer and 1 fully connected layer**\n",
    "- Train your network. Use Keras to train your network based on your network structure. Describe your training procedure. Plot the following:\n",
    "    1. Training and validation loss vs. training iterations.\n",
    "    2. Training and validation accuracy vs. training iterations.\n",
    "- Report a final test result on 100 testing examples.\n",
    "- Give detailed explanation of your code\n",
    "\n",
    "\n",
    "- *Bonus*: you can use more train/test data to build a stronger model\n",
    "\n",
    "You may want to check [Keras documentation](http://keras.io) for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#used newer version of keras, final accuracy about 50%\n",
    "#might not work in older versions\n",
    "#Che Wang\n",
    "\n",
    "# some setup code\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "# A bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "print('X_train shape:', X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize some examples from the dataset.\n",
    "# We show a few examples of training images from each class.\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "\n",
    "#plt.imshow(X_train[0])\n",
    "#print(y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 train samples\n",
      "100 test samples\n",
      "x_train shape: (1000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Subsample the data for more efficient code execution in this exercise\n",
    "num_training = 1000\n",
    "mask = list(range(num_training))\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "num_test = 100\n",
    "mask = list(range(num_test))\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "# because Keras wants something called \"one-hot\" (https://en.wikipedia.org/wiki/One-hot) to be labels\n",
    "nb_classes = 10\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "# the CIFAR10 images are RGB\n",
    "img_channels = 3\n",
    "\n",
    "#this can deal with both tf and theano\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    X_train = x_train.reshape(X_train.shape[0], img_channels, img_rows, img_cols)\n",
    "    X_test = x_test.reshape(X_test.shape[0], img_channels, img_rows, img_cols)\n",
    "    input_shape = (img_channels, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, img_channels)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, img_channels)\n",
    "    input_shape = (img_rows, img_cols, img_channels)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "#then data normalization\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('x_train shape:', X_train.shape)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please complete the rest of the notebook: Build and Train A CNN Model\n",
    "Remember we are training on a very small subset of CIFAR 10, so it is easy to overfit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32 \n",
    "nb_epoch = 50\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),padding= 'same',\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.001, decay=1e-6)\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=opt, #keras.optimizers.Adadelta(0.01),\n",
    "              metrics=['accuracy'])\n",
    "### PLEASE PUT YOUR CODE HERE!\n",
    "### Add Convolution, Activation and Pooling layers, compile your model, and fit it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test your model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/300\n",
      "1000/1000 [==============================] - 13s - loss: 2.3350 - acc: 0.1050 - val_loss: 2.2911 - val_acc: 0.1200\n",
      "Epoch 2/300\n",
      "1000/1000 [==============================] - 10s - loss: 2.2676 - acc: 0.1540 - val_loss: 2.2285 - val_acc: 0.1600\n",
      "Epoch 3/300\n",
      "1000/1000 [==============================] - 10s - loss: 2.1943 - acc: 0.1770 - val_loss: 2.1679 - val_acc: 0.1300\n",
      "Epoch 4/300\n",
      "1000/1000 [==============================] - 11s - loss: 2.1431 - acc: 0.1950 - val_loss: 2.0269 - val_acc: 0.3400\n",
      "Epoch 5/300\n",
      "1000/1000 [==============================] - 10s - loss: 2.0223 - acc: 0.2560 - val_loss: 1.9304 - val_acc: 0.2500\n",
      "Epoch 6/300\n",
      "1000/1000 [==============================] - 9s - loss: 1.9406 - acc: 0.2820 - val_loss: 2.2242 - val_acc: 0.2700\n",
      "Epoch 7/300\n",
      "1000/1000 [==============================] - 9s - loss: 1.9658 - acc: 0.2760 - val_loss: 1.9466 - val_acc: 0.2700\n",
      "Epoch 8/300\n",
      "1000/1000 [==============================] - 10s - loss: 1.8845 - acc: 0.2850 - val_loss: 2.1179 - val_acc: 0.1900\n",
      "Epoch 9/300\n",
      "1000/1000 [==============================] - 11s - loss: 1.8191 - acc: 0.3120 - val_loss: 1.8721 - val_acc: 0.3400\n",
      "Epoch 10/300\n",
      "1000/1000 [==============================] - 11s - loss: 1.8298 - acc: 0.3080 - val_loss: 1.8343 - val_acc: 0.3600\n",
      "Epoch 11/300\n",
      "1000/1000 [==============================] - 10s - loss: 1.7789 - acc: 0.3500 - val_loss: 1.7974 - val_acc: 0.3800\n",
      "Epoch 12/300\n",
      "1000/1000 [==============================] - 10s - loss: 1.7570 - acc: 0.3510 - val_loss: 1.8023 - val_acc: 0.3500\n",
      "Epoch 13/300\n",
      "1000/1000 [==============================] - 13s - loss: 1.7298 - acc: 0.3670 - val_loss: 1.9791 - val_acc: 0.3400\n",
      "Epoch 14/300\n",
      "1000/1000 [==============================] - 10s - loss: 1.6538 - acc: 0.3830 - val_loss: 2.0439 - val_acc: 0.3600\n",
      "Epoch 15/300\n",
      "1000/1000 [==============================] - 10s - loss: 1.6524 - acc: 0.3840 - val_loss: 1.7301 - val_acc: 0.4600\n",
      "Epoch 16/300\n",
      "1000/1000 [==============================] - 11s - loss: 1.5782 - acc: 0.4410 - val_loss: 2.1809 - val_acc: 0.2700\n",
      "Epoch 17/300\n",
      "1000/1000 [==============================] - 12s - loss: 1.5806 - acc: 0.4120 - val_loss: 1.7966 - val_acc: 0.4100\n",
      "Epoch 18/300\n",
      "1000/1000 [==============================] - 13s - loss: 1.5661 - acc: 0.4070 - val_loss: 1.6099 - val_acc: 0.4400\n",
      "Epoch 19/300\n",
      "1000/1000 [==============================] - 13s - loss: 1.5183 - acc: 0.4490 - val_loss: 1.6632 - val_acc: 0.4100\n",
      "Epoch 20/300\n",
      "1000/1000 [==============================] - 12s - loss: 1.4954 - acc: 0.4290 - val_loss: 1.7044 - val_acc: 0.4600\n",
      "Epoch 21/300\n",
      "1000/1000 [==============================] - 12s - loss: 1.4928 - acc: 0.4400 - val_loss: 1.7288 - val_acc: 0.4000\n",
      "Epoch 22/300\n",
      "1000/1000 [==============================] - 11s - loss: 1.4650 - acc: 0.4580 - val_loss: 1.6541 - val_acc: 0.4500\n",
      "Epoch 23/300\n",
      "1000/1000 [==============================] - 10s - loss: 1.4227 - acc: 0.4540 - val_loss: 1.6740 - val_acc: 0.4600\n",
      "Epoch 24/300\n",
      "1000/1000 [==============================] - 11s - loss: 1.4352 - acc: 0.4640 - val_loss: 1.7166 - val_acc: 0.3900\n",
      "Epoch 25/300\n",
      "1000/1000 [==============================] - 10s - loss: 1.3604 - acc: 0.5010 - val_loss: 2.0653 - val_acc: 0.3400\n",
      "Epoch 26/300\n",
      "1000/1000 [==============================] - 10s - loss: 1.3555 - acc: 0.5180 - val_loss: 1.7080 - val_acc: 0.4400\n",
      "Epoch 27/300\n",
      "1000/1000 [==============================] - 12s - loss: 1.2908 - acc: 0.5250 - val_loss: 1.6709 - val_acc: 0.3900\n",
      "Epoch 28/300\n",
      "1000/1000 [==============================] - 12s - loss: 1.3233 - acc: 0.5120 - val_loss: 1.5791 - val_acc: 0.4500\n",
      "Epoch 29/300\n",
      "1000/1000 [==============================] - 10s - loss: 1.2474 - acc: 0.5590 - val_loss: 1.9395 - val_acc: 0.3600\n",
      "Epoch 30/300\n",
      "1000/1000 [==============================] - 11s - loss: 1.2659 - acc: 0.5210 - val_loss: 1.5134 - val_acc: 0.4500\n",
      "Epoch 31/300\n",
      "1000/1000 [==============================] - 11s - loss: 1.2023 - acc: 0.5570 - val_loss: 1.7940 - val_acc: 0.4800\n",
      "Epoch 32/300\n",
      "1000/1000 [==============================] - 10s - loss: 1.2414 - acc: 0.5310 - val_loss: 1.5587 - val_acc: 0.4700\n",
      "Epoch 33/300\n",
      "1000/1000 [==============================] - 11s - loss: 1.1825 - acc: 0.5690 - val_loss: 1.6774 - val_acc: 0.3700\n",
      "Epoch 34/300\n",
      "1000/1000 [==============================] - 11s - loss: 1.1406 - acc: 0.5890 - val_loss: 1.5938 - val_acc: 0.4800\n",
      "Epoch 35/300\n",
      "1000/1000 [==============================] - 11s - loss: 1.1727 - acc: 0.5670 - val_loss: 1.6351 - val_acc: 0.4500\n",
      "Epoch 36/300\n",
      "1000/1000 [==============================] - 11s - loss: 1.0945 - acc: 0.5980 - val_loss: 1.8240 - val_acc: 0.4300\n",
      "Epoch 37/300\n",
      "1000/1000 [==============================] - 12s - loss: 1.0747 - acc: 0.5980 - val_loss: 1.6807 - val_acc: 0.4700\n",
      "Epoch 38/300\n",
      "1000/1000 [==============================] - 10s - loss: 1.1000 - acc: 0.5850 - val_loss: 1.8639 - val_acc: 0.3900\n",
      "Epoch 39/300\n",
      "1000/1000 [==============================] - 9s - loss: 1.0908 - acc: 0.6090 - val_loss: 1.5382 - val_acc: 0.5100\n",
      "Epoch 40/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.9871 - acc: 0.6380 - val_loss: 1.5353 - val_acc: 0.5200\n",
      "Epoch 41/300\n",
      "1000/1000 [==============================] - 11s - loss: 1.0118 - acc: 0.6240 - val_loss: 1.6168 - val_acc: 0.4500\n",
      "Epoch 42/300\n",
      "1000/1000 [==============================] - 12s - loss: 1.0239 - acc: 0.6230 - val_loss: 1.7981 - val_acc: 0.4300\n",
      "Epoch 43/300\n",
      "1000/1000 [==============================] - 13s - loss: 0.9628 - acc: 0.6440 - val_loss: 1.6440 - val_acc: 0.4900\n",
      "Epoch 44/300\n",
      "1000/1000 [==============================] - 13s - loss: 1.0012 - acc: 0.6400 - val_loss: 1.5763 - val_acc: 0.5200\n",
      "Epoch 45/300\n",
      "1000/1000 [==============================] - 12s - loss: 0.8876 - acc: 0.6790 - val_loss: 1.5993 - val_acc: 0.4900\n",
      "Epoch 46/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.9419 - acc: 0.6480 - val_loss: 1.5820 - val_acc: 0.4800\n",
      "Epoch 47/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.8888 - acc: 0.6890 - val_loss: 2.3211 - val_acc: 0.4000\n",
      "Epoch 48/300\n",
      "1000/1000 [==============================] - 11s - loss: 0.8690 - acc: 0.6940 - val_loss: 1.5156 - val_acc: 0.5300\n",
      "Epoch 49/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.8194 - acc: 0.6990 - val_loss: 1.7343 - val_acc: 0.4700\n",
      "Epoch 50/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.8627 - acc: 0.7030 - val_loss: 1.7140 - val_acc: 0.5200\n",
      "Epoch 51/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.8256 - acc: 0.7040 - val_loss: 1.6548 - val_acc: 0.4700\n",
      "Epoch 52/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.7966 - acc: 0.7250 - val_loss: 1.5839 - val_acc: 0.5200\n",
      "Epoch 53/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.7924 - acc: 0.7210 - val_loss: 1.6329 - val_acc: 0.5000\n",
      "Epoch 54/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.7769 - acc: 0.7160 - val_loss: 1.7134 - val_acc: 0.4900\n",
      "Epoch 55/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.7706 - acc: 0.7060 - val_loss: 1.8705 - val_acc: 0.5100\n",
      "Epoch 56/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.7288 - acc: 0.7530 - val_loss: 1.5615 - val_acc: 0.5500\n",
      "Epoch 57/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.7280 - acc: 0.7340 - val_loss: 1.5437 - val_acc: 0.5400\n",
      "Epoch 58/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.7418 - acc: 0.7530 - val_loss: 1.8029 - val_acc: 0.4900\n",
      "Epoch 59/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.7471 - acc: 0.7420 - val_loss: 1.8502 - val_acc: 0.4600\n",
      "Epoch 60/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.7025 - acc: 0.7390 - val_loss: 1.9486 - val_acc: 0.4700\n",
      "Epoch 61/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.6785 - acc: 0.7580 - val_loss: 1.7866 - val_acc: 0.4900\n",
      "Epoch 62/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.6386 - acc: 0.7630 - val_loss: 1.8179 - val_acc: 0.4600\n",
      "Epoch 63/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.6595 - acc: 0.7560 - val_loss: 1.7626 - val_acc: 0.4700\n",
      "Epoch 64/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.7024 - acc: 0.7540 - val_loss: 1.9828 - val_acc: 0.4300\n",
      "Epoch 65/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.6507 - acc: 0.7740 - val_loss: 1.8550 - val_acc: 0.5000\n",
      "Epoch 66/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.6195 - acc: 0.7760 - val_loss: 1.6759 - val_acc: 0.5300\n",
      "Epoch 67/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.6816 - acc: 0.7640 - val_loss: 1.7647 - val_acc: 0.5300\n",
      "Epoch 68/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.5903 - acc: 0.7880 - val_loss: 1.8453 - val_acc: 0.5100\n",
      "Epoch 69/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.5923 - acc: 0.7820 - val_loss: 1.6996 - val_acc: 0.5500\n",
      "Epoch 70/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.5665 - acc: 0.7830 - val_loss: 1.9523 - val_acc: 0.5300\n",
      "Epoch 71/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.6135 - acc: 0.7780 - val_loss: 1.7394 - val_acc: 0.4900\n",
      "Epoch 72/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.5343 - acc: 0.8100 - val_loss: 2.1067 - val_acc: 0.4600\n",
      "Epoch 73/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.5240 - acc: 0.8070 - val_loss: 2.4788 - val_acc: 0.3700\n",
      "Epoch 74/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.5891 - acc: 0.7990 - val_loss: 1.9573 - val_acc: 0.5000\n",
      "Epoch 75/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.5541 - acc: 0.8120 - val_loss: 1.9976 - val_acc: 0.5500\n",
      "Epoch 76/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.5290 - acc: 0.8060 - val_loss: 2.0908 - val_acc: 0.4500\n",
      "Epoch 77/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.4971 - acc: 0.8220 - val_loss: 1.9199 - val_acc: 0.4700\n",
      "Epoch 78/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.5084 - acc: 0.8190 - val_loss: 2.1693 - val_acc: 0.5000\n",
      "Epoch 79/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.5325 - acc: 0.8170 - val_loss: 1.7606 - val_acc: 0.5200\n",
      "Epoch 80/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.4727 - acc: 0.8230 - val_loss: 1.7981 - val_acc: 0.5700\n",
      "Epoch 81/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.4449 - acc: 0.8240 - val_loss: 1.7674 - val_acc: 0.5500\n",
      "Epoch 82/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.5248 - acc: 0.8110 - val_loss: 1.7287 - val_acc: 0.5100\n",
      "Epoch 83/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.4934 - acc: 0.8360 - val_loss: 1.9783 - val_acc: 0.4800\n",
      "Epoch 84/300\n",
      "1000/1000 [==============================] - 12s - loss: 0.4877 - acc: 0.8370 - val_loss: 1.7874 - val_acc: 0.5000\n",
      "Epoch 85/300\n",
      "1000/1000 [==============================] - 11s - loss: 0.4609 - acc: 0.8270 - val_loss: 1.8591 - val_acc: 0.5200\n",
      "Epoch 86/300\n",
      "1000/1000 [==============================] - 11s - loss: 0.4159 - acc: 0.8560 - val_loss: 1.9646 - val_acc: 0.5300\n",
      "Epoch 87/300\n",
      "1000/1000 [==============================] - 11s - loss: 0.4879 - acc: 0.8380 - val_loss: 2.1473 - val_acc: 0.5300\n",
      "Epoch 88/300\n",
      "1000/1000 [==============================] - 11s - loss: 0.5015 - acc: 0.8320 - val_loss: 1.8777 - val_acc: 0.5000\n",
      "Epoch 89/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.4723 - acc: 0.8360 - val_loss: 2.0369 - val_acc: 0.4900\n",
      "Epoch 90/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.4580 - acc: 0.8270 - val_loss: 2.1230 - val_acc: 0.4200\n",
      "Epoch 91/300\n",
      "1000/1000 [==============================] - 11s - loss: 0.4905 - acc: 0.8380 - val_loss: 2.1158 - val_acc: 0.4900\n",
      "Epoch 92/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.4724 - acc: 0.8270 - val_loss: 1.9039 - val_acc: 0.4800\n",
      "Epoch 93/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.4376 - acc: 0.8470 - val_loss: 1.8596 - val_acc: 0.5500\n",
      "Epoch 94/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.3868 - acc: 0.8660 - val_loss: 2.3151 - val_acc: 0.5500\n",
      "Epoch 95/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.4314 - acc: 0.8600 - val_loss: 2.0163 - val_acc: 0.5300\n",
      "Epoch 96/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.4452 - acc: 0.8420 - val_loss: 1.6906 - val_acc: 0.5600\n",
      "Epoch 97/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.4015 - acc: 0.8530 - val_loss: 2.6306 - val_acc: 0.4800\n",
      "Epoch 98/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.4435 - acc: 0.8550 - val_loss: 2.0136 - val_acc: 0.4500\n",
      "Epoch 99/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.3802 - acc: 0.8680 - val_loss: 2.2507 - val_acc: 0.4500\n",
      "Epoch 100/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.3950 - acc: 0.8660 - val_loss: 2.3342 - val_acc: 0.5200\n",
      "Epoch 101/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.3989 - acc: 0.8640 - val_loss: 2.0960 - val_acc: 0.5000\n",
      "Epoch 102/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.4134 - acc: 0.8630 - val_loss: 1.8567 - val_acc: 0.5100\n",
      "Epoch 103/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.3377 - acc: 0.8830 - val_loss: 2.1686 - val_acc: 0.4600\n",
      "Epoch 104/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.3908 - acc: 0.8710 - val_loss: 1.9711 - val_acc: 0.5400\n",
      "Epoch 105/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.4356 - acc: 0.8580 - val_loss: 1.9484 - val_acc: 0.5200\n",
      "Epoch 106/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.3785 - acc: 0.8710 - val_loss: 2.3688 - val_acc: 0.4600\n",
      "Epoch 107/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.3940 - acc: 0.8630 - val_loss: 2.1649 - val_acc: 0.4600\n",
      "Epoch 108/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.4070 - acc: 0.8680 - val_loss: 2.7011 - val_acc: 0.4300\n",
      "Epoch 109/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.3970 - acc: 0.8750 - val_loss: 2.7141 - val_acc: 0.4200\n",
      "Epoch 110/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.4099 - acc: 0.8710 - val_loss: 2.1166 - val_acc: 0.5800\n",
      "Epoch 111/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.3765 - acc: 0.8810 - val_loss: 2.0921 - val_acc: 0.5400\n",
      "Epoch 112/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.3566 - acc: 0.8790 - val_loss: 2.2660 - val_acc: 0.5400\n",
      "Epoch 113/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.3472 - acc: 0.8850 - val_loss: 2.0715 - val_acc: 0.5000\n",
      "Epoch 114/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.3675 - acc: 0.8800 - val_loss: 1.9185 - val_acc: 0.5400\n",
      "Epoch 115/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.3285 - acc: 0.8990 - val_loss: 2.0760 - val_acc: 0.5000\n",
      "Epoch 116/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.3247 - acc: 0.8810 - val_loss: 2.0833 - val_acc: 0.5100\n",
      "Epoch 117/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.3766 - acc: 0.8660 - val_loss: 2.1220 - val_acc: 0.5200\n",
      "Epoch 118/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.3217 - acc: 0.8840 - val_loss: 2.1764 - val_acc: 0.5300\n",
      "Epoch 119/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.4087 - acc: 0.8620 - val_loss: 2.1788 - val_acc: 0.5100\n",
      "Epoch 120/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.3085 - acc: 0.8940 - val_loss: 1.9091 - val_acc: 0.5700\n",
      "Epoch 121/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.3903 - acc: 0.8830 - val_loss: 2.1865 - val_acc: 0.5500\n",
      "Epoch 122/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.3347 - acc: 0.8860 - val_loss: 2.1902 - val_acc: 0.5400\n",
      "Epoch 123/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.3497 - acc: 0.8910 - val_loss: 2.1224 - val_acc: 0.5700\n",
      "Epoch 124/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.3978 - acc: 0.8730 - val_loss: 1.9695 - val_acc: 0.5400\n",
      "Epoch 125/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.3127 - acc: 0.8910 - val_loss: 2.5258 - val_acc: 0.5000\n",
      "Epoch 126/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.3317 - acc: 0.8850 - val_loss: 2.1384 - val_acc: 0.5700\n",
      "Epoch 127/300\n",
      "1000/1000 [==============================] - 9s - loss: 0.3273 - acc: 0.8970 - val_loss: 2.2040 - val_acc: 0.5800\n",
      "Epoch 128/300\n",
      "1000/1000 [==============================] - 10s - loss: 0.3017 - acc: 0.9020 - val_loss: 2.1824 - val_acc: 0.5400\n",
      "Epoch 129/300\n",
      "1000/1000 [==============================] - 14s - loss: 0.3575 - acc: 0.8690 - val_loss: 2.1818 - val_acc: 0.5300\n",
      "Epoch 130/300\n",
      "1000/1000 [==============================] - 3648s - loss: 0.3086 - acc: 0.9060 - val_loss: 2.3391 - val_acc: 0.5100\n",
      "Epoch 131/300\n",
      "1000/1000 [==============================] - 12s - loss: 0.2721 - acc: 0.9160 - val_loss: 2.2459 - val_acc: 0.5200\n",
      "Epoch 132/300\n",
      "1000/1000 [==============================] - 16s - loss: 0.3276 - acc: 0.8900 - val_loss: 2.2810 - val_acc: 0.5300\n",
      "Epoch 133/300\n",
      " 416/1000 [===========>..................] - ETA: 7s - loss: 0.3484 - acc: 0.8750"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f5950beab314>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           validation_data=(X_test, Y_test))\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/watcher/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    843\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/watcher/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/watcher/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/watcher/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2073\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/watcher/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/watcher/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/watcher/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/watcher/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/watcher/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=nb_epoch,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
